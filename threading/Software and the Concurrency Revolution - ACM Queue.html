<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><script async="" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/cbgapi.loaded_1"></script><script async="" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/cbgapi.loaded_0"></script><script gapi_processed="true" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/plusone.js" async="" type="text/javascript"></script><script src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/all.js" id="facebook-jssdk"></script><script src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/widgets.js" id="twitter-wjs"></script><script src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/dc.js" async="" type="text/javascript"></script><script type="text/javascript" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/cfform.js"></script>
<script type="text/javascript" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/masks.js"></script>














	  
	  <title>Software and the Concurrency Revolution - ACM Queue</title>
	  <meta name="description" value="
&lt;p&gt;Leveraging the full power of multicore processors demands new
tools and new thinking from the software industry.&lt;br&gt;
Concurrency has long been touted as the &quot;next big thing&quot; and &quot;the
way of the future,&quot; but for the past 30 years, mainstream software
development has been able to ignore it. Our parallel future has
finally arrived: new machines will be parallel machines, and this
will require major changes in the way we develop software. The
introductory article in this issue (&quot;The Future of Microprocessors&quot;
by Kunle Olukotun and Lance Hammond) describes the hardware
imperatives behind this shift in computer architecture from
uniprocessors to multicore processors, also known as CMPs (chip
multiprocessors). (For related analysis, see &quot;The Free Lunch Is
Over: A Fundamental Turn Toward Concurrency in Software.&quot;)&lt;/p&gt;
">
	  <meta name="keywords" value="Concurrency">

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="shortcut icon" href="http://queue.acm.org/favicon.ico">

<script type="text/javascript" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/jquery-1.js"></script>
<script type="text/javascript" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/jquery.js"></script>
<script type="text/javascript" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/global.js"></script>



<link rel="alternate" type="application/rss+xml" title="Latest Queue Content RSS 2.0" href="http://queue.acm.org/rss/feeds/latestitems.xml">
<link rel="alternate" type="application/rss+xml" title="All Queue Content RSS 2.0" href="http://queue.acm.org/rss/feeds/queuecontent.xml">
<link rel="alternate" type="application/rss+xml" title="Curmudgeon RSS 2.0" href="http://queue.acm.org/rss/feeds/curmudgeon.xml">
<link rel="alternate" type="application/rss+xml" title="Opinion RSS 2.0" href="http://queue.acm.org/rss/feeds/opinion.xml">
<link rel="alternate" type="application/rss+xml" title="Kode Vicious RSS 2.0" href="http://queue.acm.org/rss/feeds/kodevicious.xml">
<link rel="alternate" type="application/rss+xml" title="ACM TechNews RSS" href="http://www.infoinc.com/acm/TechNews.rss">
<link rel="alternate" type="application/rss+xml" title="Washington Updates RSS" href="http://usacm.acm.org/weblog2/?feed=rss2">
<link rel="alternate" type="application/rss+xml" title="RISKS Forum RSS" href="http://queue.acm.org/rss/feeds/risksforum.xml">


<link rel="alternate" type="application/rss+xml" title="AI RSS 2.0" href="http://queue.acm.org/rss/feeds/ai.xml">

<link rel="alternate" type="application/rss+xml" title="API Design RSS 2.0" href="http://queue.acm.org/rss/feeds/apidesign.xml">

<link rel="alternate" type="application/rss+xml" title="Bioscience RSS 2.0" href="http://queue.acm.org/rss/feeds/bioscience.xml">

<link rel="alternate" type="application/rss+xml" title="Compliance RSS 2.0" href="http://queue.acm.org/rss/feeds/compliance.xml">

<link rel="alternate" type="application/rss+xml" title="Component Technologies RSS 2.0" href="http://queue.acm.org/rss/feeds/componenttechnologies.xml">

<link rel="alternate" type="application/rss+xml" title="Computer Architecture RSS 2.0" href="http://queue.acm.org/rss/feeds/computerarchitecture.xml">

<link rel="alternate" type="application/rss+xml" title="Concurrency RSS 2.0" href="http://queue.acm.org/rss/feeds/concurrency.xml">

<link rel="alternate" type="application/rss+xml" title="DSPs RSS 2.0" href="http://queue.acm.org/rss/feeds/dsps.xml">

<link rel="alternate" type="application/rss+xml" title="Databases RSS 2.0" href="http://queue.acm.org/rss/feeds/databases.xml">

<link rel="alternate" type="application/rss+xml" title="Development RSS 2.0" href="http://queue.acm.org/rss/feeds/development.xml">

<link rel="alternate" type="application/rss+xml" title="Distributed Computing RSS 2.0" href="http://queue.acm.org/rss/feeds/distributedcomputing.xml">

<link rel="alternate" type="application/rss+xml" title="Distributed Development RSS 2.0" href="http://queue.acm.org/rss/feeds/distributeddevelopment.xml">

<link rel="alternate" type="application/rss+xml" title="Education RSS 2.0" href="http://queue.acm.org/rss/feeds/education.xml">

<link rel="alternate" type="application/rss+xml" title="Email and IM RSS 2.0" href="http://queue.acm.org/rss/feeds/emailandim.xml">

<link rel="alternate" type="application/rss+xml" title="Embedded Systems RSS 2.0" href="http://queue.acm.org/rss/feeds/embeddedsystems.xml">

<link rel="alternate" type="application/rss+xml" title="Failure and Recovery RSS 2.0" href="http://queue.acm.org/rss/feeds/failureandrecovery.xml">

<link rel="alternate" type="application/rss+xml" title="File Systems and Storage RSS 2.0" href="http://queue.acm.org/rss/feeds/filesystemsandstorage.xml">

<link rel="alternate" type="application/rss+xml" title="Game Development RSS 2.0" href="http://queue.acm.org/rss/feeds/gamedevelopment.xml">

<link rel="alternate" type="application/rss+xml" title="Graphics RSS 2.0" href="http://queue.acm.org/rss/feeds/graphics.xml">

<link rel="alternate" type="application/rss+xml" title="HCI RSS 2.0" href="http://queue.acm.org/rss/feeds/hci.xml">

<link rel="alternate" type="application/rss+xml" title="Managing Megaservices RSS 2.0" href="http://queue.acm.org/rss/feeds/managingmegaservices.xml">

<link rel="alternate" type="application/rss+xml" title="Mobile Computing RSS 2.0" href="http://queue.acm.org/rss/feeds/mobilecomputing.xml">

<link rel="alternate" type="application/rss+xml" title="Networks RSS 2.0" href="http://queue.acm.org/rss/feeds/networks.xml">

<link rel="alternate" type="application/rss+xml" title="Object-Relational Mapping RSS 2.0" href="http://queue.acm.org/rss/feeds/object-relationalmapping.xml">

<link rel="alternate" type="application/rss+xml" title="Open Source RSS 2.0" href="http://queue.acm.org/rss/feeds/opensource.xml">

<link rel="alternate" type="application/rss+xml" title="Patching and Deployment RSS 2.0" href="http://queue.acm.org/rss/feeds/patchinganddeployment.xml">

<link rel="alternate" type="application/rss+xml" title="Performance RSS 2.0" href="http://queue.acm.org/rss/feeds/performance.xml">

<link rel="alternate" type="application/rss+xml" title="Power Management RSS 2.0" href="http://queue.acm.org/rss/feeds/powermanagement.xml">

<link rel="alternate" type="application/rss+xml" title="Privacy and Rights RSS 2.0" href="http://queue.acm.org/rss/feeds/privacyandrights.xml">

<link rel="alternate" type="application/rss+xml" title="Processors RSS 2.0" href="http://queue.acm.org/rss/feeds/processors.xml">

<link rel="alternate" type="application/rss+xml" title="Programming Languages RSS 2.0" href="http://queue.acm.org/rss/feeds/programminglanguages.xml">

<link rel="alternate" type="application/rss+xml" title="Purpose-built Systems RSS 2.0" href="http://queue.acm.org/rss/feeds/purpose-builtsystems.xml">

<link rel="alternate" type="application/rss+xml" title="Quality Assurance RSS 2.0" href="http://queue.acm.org/rss/feeds/qualityassurance.xml">

<link rel="alternate" type="application/rss+xml" title="RFID RSS 2.0" href="http://queue.acm.org/rss/feeds/rfid.xml">

<link rel="alternate" type="application/rss+xml" title="SIP RSS 2.0" href="http://queue.acm.org/rss/feeds/sip.xml">

<link rel="alternate" type="application/rss+xml" title="Search Engines RSS 2.0" href="http://queue.acm.org/rss/feeds/searchengines.xml">

<link rel="alternate" type="application/rss+xml" title="Security RSS 2.0" href="http://queue.acm.org/rss/feeds/security.xml">

<link rel="alternate" type="application/rss+xml" title="Semi-structured Data RSS 2.0" href="http://queue.acm.org/rss/feeds/semi-structureddata.xml">

<link rel="alternate" type="application/rss+xml" title="Social Computing RSS 2.0" href="http://queue.acm.org/rss/feeds/socialcomputing.xml">

<link rel="alternate" type="application/rss+xml" title="System Administration RSS 2.0" href="http://queue.acm.org/rss/feeds/systemadministration.xml">

<link rel="alternate" type="application/rss+xml" title="System Evolution RSS 2.0" href="http://queue.acm.org/rss/feeds/systemevolution.xml">

<link rel="alternate" type="application/rss+xml" title="Virtual Machines RSS 2.0" href="http://queue.acm.org/rss/feeds/virtualmachines.xml">

<link rel="alternate" type="application/rss+xml" title="Virtualization RSS 2.0" href="http://queue.acm.org/rss/feeds/virtualization.xml">

<link rel="alternate" type="application/rss+xml" title="VoIP RSS 2.0" href="http://queue.acm.org/rss/feeds/voip.xml">

<link rel="alternate" type="application/rss+xml" title="Web Development RSS 2.0" href="http://queue.acm.org/rss/feeds/webdevelopment.xml">

<link rel="alternate" type="application/rss+xml" title="Web Security RSS 2.0" href="http://queue.acm.org/rss/feeds/websecurity.xml">

<link rel="alternate" type="application/rss+xml" title="Web Services RSS 2.0" href="http://queue.acm.org/rss/feeds/webservices.xml">

<link rel="alternate" type="application/rss+xml" title="Workflow Systems RSS 2.0" href="http://queue.acm.org/rss/feeds/workflowsystems.xml">



<script type="text/javascript">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-6562869-1']);
_gaq.push(['_trackPageview']);
(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'stats.g.doubleclick.net/dc.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
</script>

<script type="text/javascript">
function plusone_vote( obj ) {
_gaq.push(['_trackEvent','plusone',obj.state]);
}
</script>





<style>
body {
	font-family: jaf-bernino-sans, 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Verdana, sans-serif;
	color: #333;
}
div.container p {
	line-height: 1.65em;
}
h1 {
	font-size: 32px;
}
h3 {
	font-size: 18px;
}
h4 {
	font-size: 14px;
}

div.container {
	margin-left: auto;
	margin-right: auto;
}

div {
	margin: 64px;
	max-width: 640px;
	position: relative;
}
img {
    max-width: 100%;
    height: auto;
    width: auto\9; /* ie8 */
}
a {
	color: #009;
	text-decoration: none;
}
a:hover {
	text-decoration: underline;
}
hr {
	margin:64px;
}
label {
	font-size: 0.8em;
	color: #666;
}
input {
	color: #999;
}

/* NAVBAR */
.navbar {
//	position: fixed;
	background: #EEEEEE;
	top: -64px;
	z-index: 10000;
	width: 100%;
	clear: both;
	padding: 0px;
	margin: 0px;
	padding-top: 10px;
	padding-left: 10px;
	padding-right: 10px;
}

/*  SECTIONS  */
.section {
	clear: both;
	padding: 0px;
	margin: 0px;
}

/*  COLUMN SETUP  */
.col {
	display: block;
	float:left;
	margin: 1% 0 1% 1.6%;
}
.col:first-child { margin-left: 0; }


/*  GROUPING  */
.group:before,
.group:after {
	content:"";
	display:table;
}
.group:after {
	clear:both;
}
.group {
    zoom:1; /* For IE 6/7 */
}

/*  GRID OF THREE  */
.span_3_of_3 {
	width: 100%;
}
.span_2_of_3 {
	width: 66.1%;
}
.span_1_of_3 {
	width: 32.2%;
}

/*  GO FULL WIDTH AT LESS THAN 480 PIXELS */

@media only screen and (max-width: 480px) {
	.col {
		margin: 1% 0 1% 0%;
	}
}

@media only screen and (max-width: 480px) {
	.span_3_of_3 {
		width: 100%;
	}
	.span_2_of_3 {
		width: 100%;
	}
	.span_1_of_3 {
		width: 100%;
	}
}

.span_2_of_2 {
	width: 100%;
}

.span_1_of_2 {
	width: 49.2%;
}

/*  GO FULL WIDTH AT LESS THAN 480 PIXELS */

@media only screen and (max-width: 480px) {
	.span_2_of_2 {
		width: 100%;
	}
	.span_1_of_2 {
		width: 100%;
	}
}
</style>



<script type="text/javascript" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/mouseMovement.js"></script><script type="text/javascript" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/usedKeyboard.js"></script><script type="text/javascript">
<!--
    _CF_checkedit_form = function(_CF_this)
    {
        //reset on submit
        _CF_error_exists = false;
        _CF_error_messages = new Array();
        _CF_error_fields = new Object();
        _CF_FirstErrorField = null;


        //display error messages and return success
        if( _CF_error_exists )
        {
            if( _CF_error_messages.length > 0 )
            {
                // show alert() message
                _CF_onErrorAlert(_CF_error_messages);
                // set focus to first form error, if the field supports js focus().
                if( _CF_this[_CF_FirstErrorField].type == "text" )
                { _CF_this[_CF_FirstErrorField].focus(); }

            }
            return false;
        }else {
            return true;
        }
    }
//-->
</script>
<style type="text/css">.fb_hidden{position:absolute;top:-10000px;z-index:10001}.fb_invisible{display:none}.fb_reset{background:none;border:0;border-spacing:0;color:#000;cursor:auto;direction:ltr;font-family:"lucida grande", tahoma, verdana, arial, sans-serif;font-size:11px;font-style:normal;font-variant:normal;font-weight:normal;letter-spacing:normal;line-height:1;margin:0;overflow:visible;padding:0;text-align:left;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;visibility:visible;white-space:normal;word-spacing:normal}.fb_reset>div{overflow:hidden}.fb_link img{border:none}
.fb_dialog{background:rgba(82, 82, 82, .7);position:absolute;top:-10000px;z-index:10001}.fb_reset .fb_dialog_legacy{overflow:visible}.fb_dialog_advanced{padding:10px;-moz-border-radius:8px;-webkit-border-radius:8px;border-radius:8px}.fb_dialog_content{background:#fff;color:#333}.fb_dialog_close_icon{background:url(http://static.ak.fbcdn.net/rsrc.php/v2/yq/r/IE9JII6Z1Ys.png) no-repeat scroll 0 0 transparent;_background-image:url(http://static.ak.fbcdn.net/rsrc.php/v2/yL/r/s816eWC-2sl.gif);cursor:pointer;display:block;height:15px;position:absolute;right:18px;top:17px;width:15px}.fb_dialog_mobile .fb_dialog_close_icon{top:5px;left:5px;right:auto}.fb_dialog_padding{background-color:transparent;position:absolute;width:1px;z-index:-1}.fb_dialog_close_icon:hover{background:url(http://static.ak.fbcdn.net/rsrc.php/v2/yq/r/IE9JII6Z1Ys.png) no-repeat scroll 0 -15px transparent;_background-image:url(http://static.ak.fbcdn.net/rsrc.php/v2/yL/r/s816eWC-2sl.gif)}.fb_dialog_close_icon:active{background:url(http://static.ak.fbcdn.net/rsrc.php/v2/yq/r/IE9JII6Z1Ys.png) no-repeat scroll 0 -30px transparent;_background-image:url(http://static.ak.fbcdn.net/rsrc.php/v2/yL/r/s816eWC-2sl.gif)}.fb_dialog_loader{background-color:#f6f7f8;border:1px solid #606060;font-size:24px;padding:20px}.fb_dialog_top_left,.fb_dialog_top_right,.fb_dialog_bottom_left,.fb_dialog_bottom_right{height:10px;width:10px;overflow:hidden;position:absolute}.fb_dialog_top_left{background:url(http://static.ak.fbcdn.net/rsrc.php/v2/ye/r/8YeTNIlTZjm.png) no-repeat 0 0;left:-10px;top:-10px}.fb_dialog_top_right{background:url(http://static.ak.fbcdn.net/rsrc.php/v2/ye/r/8YeTNIlTZjm.png) no-repeat 0 -10px;right:-10px;top:-10px}.fb_dialog_bottom_left{background:url(http://static.ak.fbcdn.net/rsrc.php/v2/ye/r/8YeTNIlTZjm.png) no-repeat 0 -20px;bottom:-10px;left:-10px}.fb_dialog_bottom_right{background:url(http://static.ak.fbcdn.net/rsrc.php/v2/ye/r/8YeTNIlTZjm.png) no-repeat 0 -30px;right:-10px;bottom:-10px}.fb_dialog_vert_left,.fb_dialog_vert_right,.fb_dialog_horiz_top,.fb_dialog_horiz_bottom{position:absolute;background:#525252;filter:alpha(opacity=70);opacity:.7}.fb_dialog_vert_left,.fb_dialog_vert_right{width:10px;height:100%}.fb_dialog_vert_left{margin-left:-10px}.fb_dialog_vert_right{right:0;margin-right:-10px}.fb_dialog_horiz_top,.fb_dialog_horiz_bottom{width:100%;height:10px}.fb_dialog_horiz_top{margin-top:-10px}.fb_dialog_horiz_bottom{bottom:0;margin-bottom:-10px}.fb_dialog_iframe{line-height:0}.fb_dialog_content .dialog_title{background:#6d84b4;border:1px solid #3a5795;color:#fff;font-size:14px;font-weight:bold;margin:0}.fb_dialog_content .dialog_title>span{background:url(http://static.ak.fbcdn.net/rsrc.php/v2/yd/r/Cou7n-nqK52.gif) no-repeat 5px 50%;float:left;padding:5px 0 7px 26px}body.fb_hidden{-webkit-transform:none;height:100%;margin:0;overflow:visible;position:absolute;top:-10000px;left:0;width:100%}.fb_dialog.fb_dialog_mobile.loading{background:url(http://static.ak.fbcdn.net/rsrc.php/v2/ya/r/3rhSv5V8j3o.gif) white no-repeat 50% 50%;min-height:100%;min-width:100%;overflow:hidden;position:absolute;top:0;z-index:10001}.fb_dialog.fb_dialog_mobile.loading.centered{max-height:590px;min-height:590px;max-width:500px;min-width:500px}#fb-root #fb_dialog_ipad_overlay{background:rgba(0, 0, 0, .45);position:absolute;left:0;top:0;width:100%;min-height:100%;z-index:10000}#fb-root #fb_dialog_ipad_overlay.hidden{display:none}.fb_dialog.fb_dialog_mobile.loading iframe{visibility:hidden}.fb_dialog_content .dialog_header{-webkit-box-shadow:white 0 1px 1px -1px inset;background:-webkit-gradient(linear, 0% 0%, 0% 100%, from(#738ABA), to(#2C4987));border-bottom:1px solid;border-color:#1d4088;color:#fff;font:14px Helvetica, sans-serif;font-weight:bold;text-overflow:ellipsis;text-shadow:rgba(0, 30, 84, .296875) 0 -1px 0;vertical-align:middle;white-space:nowrap}.fb_dialog_content .dialog_header table{-webkit-font-smoothing:subpixel-antialiased;height:43px;width:100%}.fb_dialog_content .dialog_header td.header_left{font-size:12px;padding-left:5px;vertical-align:middle;width:60px}.fb_dialog_content .dialog_header td.header_right{font-size:12px;padding-right:5px;vertical-align:middle;width:60px}.fb_dialog_content .touchable_button{background:-webkit-gradient(linear, 0% 0%, 0% 100%, from(#4966A6), color-stop(.5, #355492), to(#2A4887));border:1px solid #2f477a;-webkit-background-clip:padding-box;-webkit-border-radius:3px;-webkit-box-shadow:rgba(0, 0, 0, .117188) 0 1px 1px inset, rgba(255, 255, 255, .167969) 0 1px 0;display:inline-block;margin-top:3px;max-width:85px;line-height:18px;padding:4px 12px;position:relative}.fb_dialog_content .dialog_header .touchable_button input{border:none;background:none;color:#fff;font:12px Helvetica, sans-serif;font-weight:bold;margin:2px -12px;padding:2px 6px 3px 6px;text-shadow:rgba(0, 30, 84, .296875) 0 -1px 0}.fb_dialog_content .dialog_header .header_center{color:#fff;font-size:16px;font-weight:bold;line-height:18px;text-align:center;vertical-align:middle}.fb_dialog_content .dialog_content{background:url(http://static.ak.fbcdn.net/rsrc.php/v2/y9/r/jKEcVPZFk-2.gif) no-repeat 50% 50%;border:1px solid #555;border-bottom:0;border-top:0;height:150px}.fb_dialog_content .dialog_footer{background:#f6f7f8;border:1px solid #555;border-top-color:#ccc;height:40px}#fb_dialog_loader_close{float:left}.fb_dialog.fb_dialog_mobile .fb_dialog_close_button{text-shadow:rgba(0, 30, 84, .296875) 0 -1px 0}.fb_dialog.fb_dialog_mobile .fb_dialog_close_icon{visibility:hidden}
.fb_iframe_widget{display:inline-block;position:relative}.fb_iframe_widget span{display:inline-block;position:relative;text-align:justify}.fb_iframe_widget iframe{position:absolute}.fb_iframe_widget_fluid_desktop,.fb_iframe_widget_fluid_desktop span,.fb_iframe_widget_fluid_desktop iframe{max-width:100%}.fb_iframe_widget_fluid_desktop iframe{min-width:220px;position:relative}.fb_iframe_widget_lift{z-index:1}.fb_hide_iframes iframe{position:relative;left:-10000px}.fb_iframe_widget_loader{position:relative;display:inline-block}.fb_iframe_widget_fluid{display:inline}.fb_iframe_widget_fluid span{width:100%}.fb_iframe_widget_loader iframe{min-height:32px;z-index:2;zoom:1}.fb_iframe_widget_loader .FB_Loader{background:url(http://static.ak.fbcdn.net/rsrc.php/v2/y9/r/jKEcVPZFk-2.gif) no-repeat;height:32px;width:32px;margin-left:-16px;position:absolute;left:50%;z-index:4}</style></head>

<body data-twttr-rendered="true">

<div class="container">
	<div class="navbar">
		<form id="form-search" name="searchform" action="results.cfm" style="float:right;">
				<input name="SearchableText" class="text" id="q" type="text">
				<br>
			
			
			<a href="http://queue.acm.org/issuedetail.cfm?issue=2773212" style="width:150px;font-size:0.7em;">Current Issue</a> &nbsp; <a href="http://queue.acm.org/pastissues.cfm" style="width:150px;font-size:0.7em;">Past Issues</a> &nbsp; <a href="http://queue.acm.org/topics.cfm" style="width:150px;font-size:0.7em;">Topics</a>
			
		</form>
		<a href="http://queue.acm.org/"><img src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/acmqueue_logo.gif"></a>

	</div>

<div style="text-align:center;">
<a href="http://queue.acm.org/applicative.cfm">The talks from the 2015 Applicative conference are now online</a>
<br><br>
<p style="border-bottom:1px solid #C0C2C4;"></p>
</div>


<br>




	
	<h4><a href="http://queue.acm.org/listing.cfm?item_topic=Concurrency&amp;qc_type=theme_list&amp;filter=Concurrency&amp;page_title=Concurrency&amp;order=desc">Concurrency</a></h4>








<p style="float:right;">
<!-- // Check for existence of associated MP3 file-->

 &nbsp;
	
		<a href="http://dl.acm.org/ft_gateway.cfm?id=1095421&amp;ftid=331774&amp;dwn=1">
			<img src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/icon_pdf.png" alt="Download PDF version of this article">
		</a>
	
</p>

<label>October 18, 2005<br><b><a class="descriptor" href="http://queue.acm.org/issuedetail.cfm?issue=1095408">Volume 3, issue 7 </a></b></label>













	
	
		
		
		
	
	
		
<p>Software and the Concurrency Revolution</p>
<p>Leveraging the full power of multicore processors demands new tools and new
  thinking from the software industry. </p>
<p>HERB SUTTER AND JAMES LARUS, MICROSOFT</p>
<p>Concurrency has long been touted as the “next big thing” and “the
  way of the future,” but for the past 30 years, mainstream software development
  has been able to ignore it. Our parallel future has finally arrived: new machines
  will be parallel machines, and this will require major changes in the way we
  develop software.</p><p>
  The introductory article in this issue (“The Future of Microprocessors” by
  Kunle Olukotun and Lance Hammond) describes the hardware imperatives behind
  this shift in computer architecture from uniprocessors to multicore processors,
  also known as CMPs (chip multiprocessors). (For related analysis, see “The
  Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software.”1) </p><p>
  In this article we focus on the implications of concurrency for software and
  its consequences for both programming languages and programmers.</p><p>
  The hardware changes that Olukotun and Hammond describe represent a fundamental
  shift in computing. For the past three decades, improvements in semiconductor
  fabrication and processor implementation produced steady increases in the speed
  at which computers executed existing sequential programs. The architectural
  changes in multicore processors benefit only concurrent applications and therefore
  have little value for most existing mainstream software. For the foreseeable
  future, today’s desktop applications will not run much faster than they
  do now. In fact, they may run slightly slower on newer chips, as individual
  cores become simpler and run at lower clock speeds to reduce power consumption
  on dense multicore processors.</p><p>
  That brings us to a fundamental turning point in software development, at least
  for mainstream software. Computers will continue to become more and more capable,
  but programs can no longer simply ride the hardware wave of increasing performance
  unless they are highly concurrent.</p><p>
  Although multicore performance is the forcing function, we have other reasons
  to want concurrency: notably, to improve responsiveness by performing work
  asynchronously instead of synchronously. For example, today’s applications
  must move work off the GUI thread so it can redraw the screen while a computation
  runs in the background.</p><p>
  But concurrency is hard. Not only are today’s languages and tools inadequate
  to transform applications into parallel programs, but also it is difficult
  to find parallelism in mainstream applications, and—worst of all—concurrency
  requires programmers to think in a way humans find difficult. </p><p>
  Nevertheless, multicore machines are the future, and we must figure out how
  to program them. The rest of this article delves into some of the reasons why
it is hard, and some possible directions for solutions.</p>
<h4>CONSEQUENCES: A NEW ERA IN SOFTWARE</h4>
<p>
  Today’s concurrent programming languages and tools are at a level comparable
  to sequential programming at the beginning of the structured programming era.
  Semaphores and coroutines are the assembler of concurrency, and locks and threads
  are the slightly higher-level structured constructs of concurrency. What we
  need is OO for concurrency—higher-level abstractions that help build
  concurrent programs, just as object-oriented abstractions help build large
  componentized programs.</p><p>
  For several reasons, the concurrency revolution is likely to be more disruptive
  than the OO revolution. First, concurrency will be integral to higher performance.
  Languages such as C ignored OO and remained usable for many programs. If concurrency
  becomes the sole path to higher-performance hardware, commercial and systems
  programming languages will be valued on their support for concurrent programming.
  Existing languages, such as C, will gain concurrent features beyond simple
  models such as pthreads. Languages that fail to support concurrent programming
  will gradually die away and remain useful only when modern hardware is unimportant.</p><p>
  The second reason that concurrency will be more disruptive than OO is that,
  although sequential programming is hard, concurrent programming is demonstrably
  more difficult. For example, context-sensitive analysis of sequential programs
  is a fundamental technique for taking calling contexts into account when analyzing
  a program. Concurrent programs also require synchronization analysis, but simultaneously
  performing both analyses is provably undecidable.2</p><p>
  Finally, humans are quickly overwhelmed by concurrency and find it much more
  difficult to reason about concurrent than sequential code. Even careful people
  miss possible interleavings among simple collections of partially ordered operations.</p>
<h4>DIFFERENCES BETWEEN CLIENT AND SERVER APPLICATIONS</h4>
<p>
  Concurrency is a challenging issue for client-side applications. For many server-based
  programs, however, concurrency is a “solved problem,” in that we
  routinely architect concurrent solutions that work well, although programming
  them and ensuring they scale can still require a huge effort. These applications
  typically have an abundance of parallelism, as they simultaneously handle many
  independent request streams. For example, a Web server or Web site independently
  executes thousands of copies of the same code on mostly nonoverlapping data.</p><p>
  In addition, these executions are well isolated and share state via an abstract
  data store, such as a database that supports highly concurrent access to structured
  data. The net effect is that code that shares data through a database can keep
  its “peaceful easy feeling”—the illusion of living in a tidy,
  single-threaded universe.</p><p>
  The world of client applications is not nearly as well structured and regular.
  A typical client application executes a relatively small computation on behalf
  of a single user, so concurrency is found by dividing a computation into finer
  pieces. These pieces, say the user interface and program’s computation,
  interact and share data in myriad ways. What makes this type of program difficult
  to execute concurrently are nonhomogeneous code; fine-grained, complicated
  interactions; and pointer-based data structures.</p>
<h4>PROGRAMMING MODELS</h4>
<p>
  Today, you can express parallelism in a number of different ways, each applicable
    to only a subset of programs. In many cases, it is difficult, without careful
    design and analysis, to know in advance which model is appropriate for a
    particular problem, and it is always tricky to combine several models when
    a given application does not fit cleanly into a single paradigm.</p><p>
  These parallel programming models differ significantly in two dimensions: the
  granularity of the parallel operations and the degree of coupling between these
  tasks. Different points in this space favor different programming models, so
  let’s examine these axes in turn.</p><p>
  Operations executed in parallel can range from single instructions, such as
  addition or multiplication, to complex programs that take hours or days to
  run. Obviously, for small operations, the overhead costs of the parallel infrastructure
  are significant; for example, parallel instruction execution generally requires
  hardware support. Multicore processors reduce communication and synchronization
  costs, as compared with conventional multiprocessors, which can reduce the
  overhead burden on smaller pieces of code. Still, in general, the finer grained
  the task, the more attention must be paid to the cost of spawning it as a separate
  task and providing its communication and synchronization.</p><p>
  The other dimension is the degree of coupling in the communication and synchronization
  between the operations. The ideal is none: operations run entirely independently
  and produce distinct outputs. In this case, the operations can run in any order,
  incur no synchronization or communications costs, and are easily programmed
  without the possibility of data races. This state of affairs is rare, as most
  concurrent programs share data among their operations. The complexity of ensuring
  correct and efficient operation increases as the operations become more diverse.
  The easiest case is executing the same code for each operation. This type of
  sharing is often regular and can be understood by analyzing only a single task.
  More challenging is irregular parallelism, in which the operations are distinct
  and the sharing patterns are more difficult to comprehend.</p>
<h4>Independent parallelism </h4>
<p>
  Perhaps the simplest and best-behaved model is independent parallelism (sometimes
    called “embarrassingly parallel tasks”), in which one or more
    operations are applied independently to each item in a data collection.</p><p>
  Fine-grained data parallelism relies on the independence of the operations
  executed concurrently. They should not share input data or results and should
  be executable without coordination. For example:</p>
<pre>double A[100][100];<br>…<br>A = A * 2;</pre>
<p>multiplies each element of a 100x100 array by 2 and stores the result in the
  same array location. Each of the 10,000 multiplications proceeds independently
  and without coordination with its peers. This is probably more concurrency
  than necessary for most computers, and its granularity is very fine, so a more
  practical approach would partition the matrix into n x m blocks and execute
  the operations on the blocks concurrently.</p><p>
  At the other end of the granularity axis, some applications, such as search
  engines, share only a large read-only database, so concurrently processing
  queries requires no coordination. Similarly, large simulations, which require
  many runs to explore a large space of input parameters, are another embarrassingly
  parallel application.</p>
<h4>Regular parallelism</h4>
<p>
  The next step beyond independent parallelism is to apply the same operation
    to a collection of data when the computations are mutually dependent. An
    operation on one piece of data is dependent on another operation if there
    is communication or synchronization between the two operations. </p><p>
  For example, consider a stencil computation that replaces each point in an
  array, the average of its four nearest neighbors:</p>
<pre>A[i, j] = (A[i-1, j] + A[i, j-1] + A[i+1, j] + A[i, j+1]) / 4;</pre>
<p>This computation requires careful coordination to ensure that an array location
  is read by its neighbors before being replaced by its average. If space is
  no concern, then the averages can be computed into a new array. In general,
  other more structured computation strategies, such as traversing the array
  in a diagonal wavefront, will produce the same result, with better cache locality
  and lower memory consumption.</p><p>
  Regular parallel programs may require synchronization or carefully orchestrated
  execution strategies to produce the correct results, but unlike general parallelism,
  the code behind the operations can be analyzed to determine how to execute
  them concurrently and what data they share. This advantage is sometimes hypothetical,
  since program analysis is an imprecise discipline, and sufficiently complex
  programs are impossible for compilers to understand and restructure.</p><p>
  At the other end of the granularity axis, computations on a Web site are typically
  independent except for accesses to a common database. The computations run
  in parallel without a significant amount of coordination beyond the database
  transactions. This ensures that concurrent access to the same data is consistently
  resolved.</p>
<h4>Unstructured parallelism </h4>
<p>
  The most general, and least disciplined, form of parallelism is when the concurrent
    computations differ, so that their data accesses are not predictable and
    need to be coordinated through explicit synchronization. This is the form
    of parallelism most common in programs written using threads and explicit
    synchronization, in which each thread has a distinct role in the program.
    In general, it is difficult to say anything specific about this form of parallelism,
    except that conflicting data accesses in two threads need explicit synchronization;
    otherwise, the program will be nondeterministic.</p>
<h4>THE PROBLEM OF SHARED STATE, AND WHY LOCKS AREN’T THE ANSWER</h4>
<p>
  Another challenging aspect of unstructured parallelism is sharing unstructured
  state. A client application typically manipulates shared memory organized as
  unpredictably interconnected graphs of objects.</p><p>
  When two tasks try to access the same object, and one could modify its state,
  if we do nothing to coordinate the tasks, we have a data race. Races are bad,
  because the concurrent tasks can read and write inconsistent or corrupted values.</p><p>
  There are a rich variety of synchronization devices that can prevent races.
  The simplest of these is a lock. Each task that wants to access a piece of
  shared data must acquire the lock for that data, perform its computation, and
  then release the lock so other operations on the data can proceed. Unfortunately,
  although locks work, they pose serious problems for modern software development.</p><p>
  A fundamental problem with locks is that they are not composable. You can’t
  take two correct lock-based pieces of code, combine them, and know that the
  result is still correct. Modern software development relies on the ability
  to compose libraries into larger programs, and so it is a serious difficulty
  that we cannot build on lock-based components without examining their implementations.</p><p>
  The composability issue arises primarily from the possibility of deadlock.
  In its simplest form, deadlock happens when two locks might be acquired by
  two tasks in opposite order: task T1 takes lock L1, task T2 takes lock L2,
  and then T1 tries to take L2 while T2 tries to take L1. Both block forever.
  Because this can happen any time two locks can be taken in opposite order,
  calling into code you don’t control while holding a lock is a recipe
  for deadlock.</p><p>
  That is exactly what extensible frameworks do, however, as they call virtual
  functions while holding a lock. Today’s best-of-breed commercial application
  frameworks all do this, including the .NET Frameworks and the Java standard
  libraries. We have gotten away with it because developers aren’t yet
  writing lots of heavily concurrent programs that do frequent locking. Many
  complex models attempt to deal with the deadlock problem—with backoff-and-retry
  protocols, for example—but they require strict discipline by programmers,
  and some introduce their own problems (e.g., livelock).</p><p>
  Techniques for avoiding deadlock by guaranteeing locks will always be acquired
  in a safe order do not compose, either. For example, lock leveling and lock
  hierarchies prevent programs from acquiring locks in conflicting order by requiring
  that all locks at a given level be acquired at once in a predetermined order,
  and that while holding locks at one level, you can acquire additional locks
  only at higher levels. Such techniques work inside a module or framework maintained
  by a team (although they’re underused in practice), but they assume control
  of an entire code base. That severely restricts their use in extensible frameworks,
  add-in systems, and other situations that bring together code written by different
  parties. </p><p>
  A more basic problem with locks is that they rely on programmers to strictly
  follow conventions. The relationship between a lock and the data that it protects
  is implicit, and it is preserved only through programmer discipline. A programmer
  must always remember to take the right lock at the right point before touching
  shared data. Conventions governing locks in a program are sometimes written
  down, but they’re almost never stated precisely enough for a tool to
  check them.</p><p>
  Locks have other more subtle problems. Locking is a global program property,
  which is difficult to localize to a single procedure, class, or framework.
  All code that accesses a piece of shared state must know and obey the locking
  convention, regardless of who wrote the code or where it resides.</p><p>
  Attempts to make synchronization a local property do not work all the time.
  Consider a popular solution such as Java’s synchronized methods. Each
  of an object’s methods can take a lock on the object, so no two threads
  can directly manipulate the object’s state simultaneously. As long as
  an object’s state is accessed only by its methods and programmers remember
  to add the synchronized declaration, this approach works.</p><p>
  There are at least three major problems with synchronized methods. First, they
  are not appropriate for types whose methods call virtual functions on other
  objects (e.g., Java’s Vector and .NET’s SyncHashTable), because
  calling into third-party code while holding a lock opens the possibility of
  deadlock. Second, synchronized methods can perform too much locking, by acquiring
  and releasing locks on all object instances, even those never shared across
  threads (typically the majority). Third, synchronized methods can also perform
  too little locking, by not preserving atomicity when a program calls multiple
  methods on an object or on different objects. As a simple example of the latter,
  consider a banking transfer:</p>
<pre>account1.Credit(amount); account2.Debit(amount)</pre>
<p>Per-object locking protects each call, but does not prevent another thread
  from seeing the inconsistent state of the two accounts between the calls. Operations
  of this type, whose atomicity does not correspond to a method call boundary,
  require additional, explicit synchronization.</p>
<h4>Lock Alternatives</h4>
<p>
  For completeness, we note two major alternatives to locks. The first is lock-free
    programming. By relying on a deep knowledge of a processor’s memory
    model, it is possible to create data structures that can be shared without
    explicit locking. Lock-free programming is difficult and fragile; inventing
    a new lock-free data-structure implementation is still often a publishable
    result.</p><p>
  The second alternative is transactional memory, which brings the central idea
  of transactions from databases into programming languages. Programmers write
  their programs as a series of explicitly atomic blocks, which appear to execute
  indivisibly, so concurrently executing operations see the shared state strictly
  before or after an atomic action executes. Although many people view transactional
  memory as a promising direction, it is still a subject of active research.</p>
<h4>WHAT WE NEED IN PROGRAMMING LANGUAGES</h4>
<p>
  We need higher-level language abstractions, including evolutionary extensions
    to current imperative languages, so that existing applications can incrementally
    become concurrent. The programming model must make concurrency easy to understand
    and reason about, not only during initial development but also during maintenance.</p>
<h4>Explicit, implicit, and automatic parallelization </h4>
<p>
  Explicit programming models provide abstractions that require programmers to
    state exactly where concurrency can occur. The major advantage of expressing
    concurrency explicitly is that it allows programmers to take full advantage
    of their application domain knowledge and express the full potential concurrency
    in the application. It has drawbacks, however. It requires new higher-level
    programming abstractions and a higher level of programmer proficiency in
    the presence of shared data.</p><p>
  Implicit programming models hide concurrency inside libraries or behind APIs,
  so that a caller retains a sequential worldview while the library performs
  the work in parallel. This approach lets naïve programmers safely use
  concurrency. Its main drawback is that some kinds of concurrency-related performance
  gains can’t be realized this way. Also, it is difficult to design interfaces
  that do not expose the concurrency in any circumstance—for example, when
  a program applies the operation to several instances of the same data.</p><p>
  Another widely studied approach is automatic parallelization, where a compiler
  attempts to find parallelism, typically in programs written in a conventional
  language such as Fortran. As appealing as it may seem, this approach has not
  worked well in practice. Accurate program analysis is necessary to understand
  a program’s potential behavior. This analysis is challenging for simple
  languages such as Fortran, and far more difficult for languages, such as C,
  that manipulate pointer-based data. Moreover, sequential programs often use
  sequential algorithms and contain little concurrency.</p>
<h4>Imperative and functional languages. </h4>
<p>
  Popular commercial programming languages (e.g., Pascal, C, C++, Java, C#) are
    imperative languages in which a programmer specifies step-by-step changes
    to variables and data structures. Fine-grained control constructs (e.g.,
    for loops), low-level data manipulations, and shared mutable object instances
    make programs in these languages difficult to analyze and automatically parallelize.</p><p>
  The common belief is that functional languages, such as Scheme, ML, or Haskell,
  could eliminate this difficulty because they are naturally suited to concurrency.
  Programs written in these languages manipulate immutable object instances,
  which pose no concurrency hazards. Moreover, without side effects, programs
  seem to have fewer constraints on execution order.</p><p>
  In practice, however, functional languages are not necessarily conducive to
  concurrency. The parallelism exposed in functional programs is typically at
  the level of procedure calls, which is impractically fine-grained for conventional
  parallel processors. Moreover, most functional languages allow some side effects
  to mutable state, and code that uses these features is difficult to parallelize
  automatically. </p><p>
  These languages reintroduce mutable state for reasons of expressibility and
  efficiency. In a purely functional language, aggregate data structures, such
  as arrays or trees, are updated by producing a copy containing a modified value.
  This technique is semantically attractive but can be terrible for performance
  (linear algorithms easily become quadratic). In addition, functional updates
  do nothing to discourage the writing of a strictly sequential algorithm, in
  which each operation waits until the previous operation updates the program’s
  state.</p><p>
  The real contribution of functional languages to concurrency comes in the higher-level
  programming style commonly employed in these languages, in which operations
  such as map or map-reduce apply computations to all elements of an aggregate
  data structure. These higher-level operations are rich sources of concurrency.
  This style of programming, fortunately, is not inherently tied to functional
  languages, but is valuable in imperative programs. </p><p>
  For example, Google Fellows Jeffrey Dean and Sanjay Ghemawat describe how Google
  uses Map-Reduce to express large-scale distributed computations.3 Imperative
  languages can judiciously add functional style extensions and thereby benefit
  from those features. This is important because the industry can’t just
  start over. To preserve the huge investment in the world’s current software,
  it is essential to incrementally add support for concurrency, while preserving
  software developers’ expertise and training in imperative languages. </p>
<h4>Better abstractions </h4>
<p>
  Most of today’s languages offer explicit programming at the level of
  threads and locks. These abstractions are low-level and difficult to reason
  about systematically. Because these constructs are a poor basis for building
  abstractions, they encourage multithreaded programming with its problems of
  arbitrary blocking and reentrancy. </p><p>
  Higher-level abstractions allow programmers to express tasks with inherent
  concurrency, which a runtime system can then combine and schedule to fit the
  hardware on the actual machine. This will enable applications that perform
  better on newer hardware. In addition, for mainstream development, programmers
  will value the illusion of sequential execution within a task.</p><p>
  Two basic examples of higher-level abstractions are asynchronous calls and
  futures. An asynchronous call is a function or method call that is nonblocking.
  The caller continues executing and, conceptually, a message is sent to a task,
  or fork, to execute operation independently. A future is a mechanism for returning
  a result from an asynchronous call; it is a placeholder for the value that
  has not yet materialized. </p><p>
  Another example of a higher-level abstraction is an active object, which conceptually
  runs on its own thread so that creating 1,000 such objects conceptually creates
  1,000 potential threads of execution. An active object behaves as a monitor,
  in that only one method of the object executes at a given time, but it requires
  no traditional locking. Rather, method calls from outside an active object
  are asynchronous messages, marshaled, queued, and pumped by the object. Active
  objects have many designs, from specialized actor languages to COM single-threaded
  apartments callable from traditional C code, and many design variables. </p><p>
  Other higher-level abstractions are needed, such as protocols to describe and
  check asynchronous message exchange. Together they should bring together a
  consistent programming model that can express typical application concurrency
  requirements across all of the major granularity levels.</p><h4>
  WHAT WE NEED IN TOOLS</h4>
  <p>
  Parallel programming, because of its unfamiliarity and intrinsic difficulty,
  is going to require better programming tools to systematically find defects,
  help debug programs, find performance bottlenecks, and aid in testing. Without
  these tools, concurrency will become an impediment that reduces developer and
  tester productivity and makes concurrent software more expensive and of lower
  quality.</p><p>
  Concurrency introduces new types of programming errors, beyond those all too
  familiar in sequential code. Data races (resulting from inadequate synchronization
  and deadlocks) and livelocks (resulting from improper synchronization) are
  difficult defects to find and understand, since their behavior is often nondeterministic
  and difficult to reproduce. Conventional methods of debugging, such as reexecuting
  a program with a breakpoint set earlier in its execution, do not work well
  for concurrent programs whose execution paths and behaviors may vary from one
  execution to the next.</p><p>
  Systematic defect detection tools are extremely valuable in this world. These
  tools use static program analysis to systematically explore all possible executions
  of a program; thus, they can catch errors that are impossible to reproduce.
  Although similar techniques, such as model checking, have been used with great
  success for finding defects in hardware, which is inherently concurrent, software
  is more difficult. The state space of a typical program is far larger than
  that of most hardware, so techniques that systematically explore an artifact’s
  states have much more work to do. In both cases, modularity and abstraction
  are the keys to making the analysis tractable. In hardware model testing, if
  you can break off the ALU (arithmetic logic unit) and analyze it independently
  of the register file, your task becomes much more tractable. </p><p>
  That brings us to a second reason why software is more difficulty to analyze:
  it is far harder to carve off pieces of a program, analyze them in isolation,
  and then combine the results to see how they work together. Shared state, unspecified
  interfaces, and undocumented interactions make this task much more challenging
  for software.</p><p>
  Defect detection tools for concurrent software comprise an active area of research.
  One promising technique from Microsoft Research called KISS (Keep it Strictly
  Sequential)4 transforms a threaded program into a sequential program whose
  execution behavior includes all possible interleaves of the original threads
  that involve no more than two context switches. The transformed program can
  then be analyzed by the large number of existing sequential tools, which then
  become concurrent defect detection tools for this bounded model.</p><p>
  Even with advances such as these, programmers are still going to need good
  debuggers that let them understand the complex and difficult-to-reproduce interactions
  in their parallel programs. There are two general techniques for collecting
  this information. The first is better logging facilities that track which messages
  were sent to which process or which thread accessed which object, so that a
  developer can look back and understand a program’s partially ordered
  execution. Developers will also want the ability to follow causality trails
  across threads (e.g., which messages to one active object, when executed, led
  to which other messages to other active objects?), replay and reorder messages
  in queues, step through asynchronous call patterns including callbacks, and
  otherwise inspect the concurrent execution of their code. The second approach
  is reverse execution, which permits a programmer to back up in a program’s
  execution history and reexecute some code. Replay debugging is an old idea,
  but its cost and complexity have been barriers to adoption. Recently, virtual
  machine monitors have reduced both factors.5 In a concurrent world, this technique
  will likely become a necessity.</p><p>
  Performance debugging and tuning will require new tools in a concurrent world
  as well. Concurrency introduces new performance bottlenecks, such as lock contention,
  cache coherence overheads, and lock convoys, which are often difficult to identify
  with simple profilers. New tools that are more aware of the underlying computer
  architecture and the concurrent structure of a program will be better able
  to identify these problems.</p><p>
  Testing, too, must change. Concurrent programs, because of their nondeterministic
  behaviors, are more difficult to test. Simple code coverage metrics, which
  track whether a statement or branch has executed, need to be extended to take
  into account the other code that is executing concurrently, or else testing
  will provide an unrealistically optimistic picture of how completely a program
  has been exercised. Moreover, simple stress tests will need to be augmented
  by more systematic techniques that use model-checking-like techniques to explore
  systems’ state spaces. For example, Verisoft has been very successful
  in using these techniques to find errors in concurrent telephone switching
  software.6 Today, many concurrent applications use length of stress testing
  to gain confidence that the application is unlikely to contain serious races.
  In the future, that will increasingly be insufficient, and software developers
  will need to be able to prove their product’s quality through rigorous
  deterministic testing instead of relying on a probabilistic confidence based
  on stress tests.</p>
<h4>PARALLELISM IS KEY</h4>
<p>
  The concurrency revolution is primarily a software revolution. The difficult
    problem is not building multicore hardware, but programming it in a way that
    lets mainstream applications benefit from the continued exponential growth
    in CPU performance.</p><p>
  The software industry needs to get back into the state where existing applications
  run faster on new hardware. To do that, we must begin writing concurrent applications
  containing at least dozens, and preferably hundreds, of separable tasks (not
  all of which need be active at a given point).</p><p>
  Concurrency also opens the possibility of new, richer computer interfaces and
  far more robust and functional software. This requires a new burst of imagination
  to find and exploit new uses for the exponentially increasing potential of
  new processors.</p><p>
  To enable such applications, programming language designers, system builders,
  and programming tool creators need to start thinking seriously about parallelism
  and find techniques better than the low-level tools of threads and explicit
  synchronization that are today’s basic building blocks of parallel programs.
  We need higher-level parallel constructs that more clearly express a programmer’s
  intent, so that the parallel architecture of a program is more visible, easily
  understood, and verifiable by tools. </p>
<h4>References</h4>
<p>
  1. Sutter, H. 2005. The free lunch is over: a fundamental turn toward concurrency
    in software. Dr. Dobb’s Journal 30 (3); <a href="http://www.gotw.ca/publications/concurrency-ddj.htm">http://www.gotw.ca/publications/concurrency-ddj.htm</a>.</p>
<p>
  2. Ramalingam, G. 2000. Context-sensitive synchronization-sensitive analysis
  is undecidable. ACM Transactions on Programming Languages and Systems 22 (2):
  416-430. </p>
<p>
  3. Dean, J., and Ghemawat, S. 2004. MapReduce: simplified data processing
  on large clusters. Proceedings of the Sixth Symposium on Operating Systems
  Design and Implementation, San Francisco, CA: 137-150.</p>
<p>
  4. Qadeer, S., and Wu, D. 2004. KISS: Keep it Simple and Sequential. Proceedings
  of the ACM SIGPLAN 2004 Conference on Programming Language Design and Implementation,
  Washington, DC: 1-13. </p>
<p>
  5. King, S. T., Dunlap, G. W., and Chen, P. M. 2005. Debugging operating systems
  with time-traveling virtual machines. Proceedings of the 2005 Annual Usenix
  Technical Conference, Anaheim, CA: 1-15. </p>
<p>
  6. Chandra, S., Godefroid, P., and Palm, C. 2002. Software model checking
  in practice: an industrial case study. Proceedings of the 24th International
  Conference on Software Engineering, Orlando, FL: 431-441. </p>
<p>HERB SUTTER is a software architect in Microsoft’s developer division.
  He chairs the ISO C++ standards committee, and is the author of four books
  and more than 200 technical papers and articles, including the widely read “The
  Free Lunch Is Over” essay on the concurrency revolution. He can be reached
  at <a href="mailto:hsutter@microsoft.com">hsutter@microsoft.com</a>.</p>
<p>
  JAMES LARUS is a senior researcher at Microsoft Research, managing SWIG (Software
  Improvement Group), which consists of the SPT (software productivity tools),
  TVM (testing, verification, and measurement), and HIP (human interactions in
  programming) research groups, and running the Singularity research project.
  Before joining Microsoft, he was an associate professor at the University of
  Wisconsin-Madison, where he co-led the Wisconsin Wind Tunnel research project.
  This DARPA- and NSF-funded project investigated new approaches to building
  and programming parallel shared-memory computers. Larus received his Ph.D.
  in computer science from the University of California at Berkeley.</p><p>
</p>

	

 <p>
 
 	
	    <img class="floatLeft" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/q%2520stamp_small.jpg" alt="acmqueue" height="45" width="26"><br><br>
	
	<em>Originally published in Queue vol. 3, no. 7</em>—
 	<br>
	see this item in the <a href="http://portal.acm.org/citation.cfm?id=1095421">ACM Digital Library</a>
 
  </p>




<br>
<iframe style="position: static; visibility: visible; width: 77px; height: 20px;" data-twttr-rendered="true" title="Twitter Tweet Button" class="twitter-share-button twitter-tweet-button twitter-share-button twitter-count-horizontal" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/tweet_button.html" allowtransparency="true" scrolling="no" id="twitter-widget-0" frameborder="0"></iframe>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

<br>

<fb:like fb-iframe-plugin-query="app_id=&amp;container_width=0&amp;href=http%3A%2F%2Fqueue.acm.org%2Fdetail.cfm%3Fid%3D1095421&amp;locale=en_US&amp;sdk=joey" fb-xfbml-state="rendered" class=" fb_iframe_widget"><span style="vertical-align: bottom; width: 450px; height: 20px;"><iframe class="" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/like.html" style="border: medium none; visibility: visible; width: 450px; height: 20px;" title="fb:like Facebook Social Plugin" scrolling="no" allowfullscreen="true" allowtransparency="true" name="f1c8ec0314f5af8" frameborder="0" height="1000px" width="1000px"></iframe></span></fb:like>

<br>

<div id="___plusone_0" style="text-indent: 0px; margin: 0px; padding: 0px; background: none repeat scroll 0% 0% transparent; border-style: none; float: none; line-height: normal; font-size: 1px; vertical-align: baseline; display: inline-block; width: 120px; height: 15px;"><iframe title="+1" data-gapiattached="true" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/fastbutton.html" name="I0_1431122820700" id="I0_1431122820700" vspace="0" tabindex="0" style="position: static; top: 0px; width: 120px; margin: 0px; border-style: none; left: 0px; visibility: visible; height: 15px;" scrolling="no" marginwidth="0" marginheight="0" hspace="0" frameborder="0" width="100%"></iframe></div>

<!-- these get hooked up to js events -->
<script type="text/javascript">
	addthis_pub             = 'acm';
	addthis_logo            = 'http://queue.acm.org/img/logo_queue_small.gif';
	addthis_logo_background = '#ffffff';
	addthis_logo_color      = '000000';
	addthis_brand           = 'ACM Queue';
	addthis_options         = 'reddit, slashdot, facebook, favorites, email, delicious, digg, technorati, blinklist, furl, myspace, google, live, more';
</script>

<!-- FB Like -->

<div class=" fb_reset" id="fb-root"><div style="position: absolute; top: -10000px; height: 0px; width: 0px;"><div><iframe src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/KTWTb9MY5lw.html" style="border: medium none;" tabindex="-1" title="Facebook Cross Domain Communication Frame" aria-hidden="true" id="fb_xdm_frame_http" scrolling="no" allowfullscreen="true" allowtransparency="true" name="fb_xdm_frame_http" frameborder="0"></iframe><iframe src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/KTWTb9MY5lw_002.html" style="border: medium none;" tabindex="-1" title="Facebook Cross Domain Communication Frame" aria-hidden="true" id="fb_xdm_frame_https" scrolling="no" allowfullscreen="true" allowtransparency="true" name="fb_xdm_frame_https" frameborder="0"></iframe></div></div><div style="position: absolute; top: -10000px; height: 0px; width: 0px;"><div></div></div></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<div id="fb-root"></div>

<!-- Place this tag after the last +1 button tag. -->
<script type="text/javascript">
  (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();
</script>

<br>
<script src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/all.js"></script>

<script>
FB.Event.subscribe('edge.create', function(targetUrl) {
  _gaq.push(['_trackSocial', 'facebook', 'like', targetUrl]);
});
</script>



<!-- EMail Link-->


<hr size="1" noshade="noshade">










Related:

	  <p>
	  <span>Spencer Rathbun</span> - <a href="http://queue.acm.org/detail.cfm?id=2742696"><b>Parallel Processing with Promises</b></a>
	  <br>
	  A simple method of writing a collaborative system
	  </p>
	  <br>

	  <p>
	  <span>Davidlohr Bueso</span> - <a href="http://queue.acm.org/detail.cfm?id=2698990"><b>Scalability Techniques for Practical Synchronization Primitives</b></a>
	  <br>
	  Designing locking primitives with performance in mind
	  </p>
	  <br>

	  <p>
	  <span>John T. Richards, Jonathan Brezin, Calvin B. Swart, Christine A. Halverson</span> - <a href="http://queue.acm.org/detail.cfm?id=2682913"><b>Productivity in Parallel Programming: A Decade of Progress</b></a>
	  <br>
	  Looking at the design and benefits of X10
	  </p>
	  <br>

	  <p>
	  <span>Andi Kleen</span> - <a href="http://queue.acm.org/detail.cfm?id=2579227"><b>Scaling Existing Lock-based Applications with Lock Elision</b></a>
	  <br>
	  Lock elision enables existing lock-based programs to achieve the performance benefits of nonblocking synchronization and fine-grain locking with minor software engineering effort.
	  </p>
	  <br>



<hr size="1" noshade="noshade">





 <h3>Comments</h3>


	
	











<form name="edit_form" id="edit_form" action="postcomment.cfm" method="post" onsubmit="return _CF_checkedit_form(this)">












	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	




	
	<input name="formfield1234567891" id="formfield1234567891" value="247" type="hidden">
	



	
	<input name="formfield1234567892" id="formfield1234567892" value="1" type="hidden">
	



	
	
	
	
	
	
	
	<input name="formfield1234567893" value="39890714,19920860" type="hidden">



	
	<span style="display:none">Leave this field empty <input name="formfield1234567894" type="text"></span>



<input name="id" value="1095421" type="Hidden">
<p>Post a Comment:</p>
<input name="Creator" id="username" size="40" alt="Submitter" title="Name" value="name" onfocus="if (this.value == 'name') {this.value = '';}" type="text">
<br>
<input name="email" id="email" size="40" value="email" onfocus="if (this.value == 'email') {this.value = '';}" type="text">
<br>
<label for="body_text">Comment: (Required - 4,000 character limit - HTML syntax is <strong>not</strong> allowed and <b>will be removed</b>)</label>
<br>
<textarea name="body_text" rows="8" id="body_text" html="No" cols="80"></textarea>
<br>
<input name="discussion_reply:method" id="discussion_reply:method" value="Post" class="context" validate="SubmitOnce" type="submit">
</form>





<hr size="1" noshade="noshade">

	<p>
	<a href="#"><img src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/logo_acm.gif"></a>
	<br>
	© 2014 ACM, Inc. All Rights Reserved.
	</p>

</div>


<iframe tabindex="-1" style="width: 1px; height: 1px; position: absolute; top: -100px;" src="Software%20and%20the%20Concurrency%20Revolution%20-%20ACM%20Queue_files/postmessageRelay.html" id="oauth2relay244587543" name="oauth2relay244587543"></iframe></body></html>